{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoint Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "import torch.nn.init\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from copy import deepcopy, copy\n",
    "from config_profile import args\n",
    "from Utils import cv2_scale36, cv2_scale, np_reshape, np_reshape64\n",
    "from Utils import L2Norm, cv2_scale, np_reshape\n",
    "from descriptor import DesNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU availability, using nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_weights_module_cell'></a>\n",
    "### Load network weights\n",
    "[BackToSection](#generate_deep_features_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "    (18): Dropout(p=0.3, inplace=False)\n",
       "    (19): Conv2d(128, 128, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
       "    (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_weight_path = \"checkpoint.pth\" # suppose you are using checkpoint.pth\n",
    "model = DesNet()\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "trained_weight = torch.load(trained_weight_path)['state_dict']\n",
    "model.load_state_dict(trained_weight)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_raw_patch_files_module_cell'></a>\n",
    "### Load raw patch files\n",
    "Assume that the raw patch file is stored as patches.pth\n",
    "\n",
    "[BackToSection](#generate_deep_features_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "patches_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([136, 20, 1, 32, 32])\n",
      "torch.Size([2720, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "patches_image_dir = \"patches_image.pt\"\n",
    "patches_image = torch.load(patches_image_dir)\n",
    "print(patches_image.shape)\n",
    "patches_image = patches_image.view(-1, 1, 32, 32).cuda()\n",
    "print(patches_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "patches_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 20, 1, 32, 32])\n",
      "torch.Size([680, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "patches_query_dir = \"patches_query.pt\"\n",
    "patches_query = torch.load(patches_query_dir)\n",
    "print(patches_query.shape)\n",
    "patches_query = patches_query.view(-1, 1, 32, 32).cuda()\n",
    "print(patches_query.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='get_deep_features_module_cell'></a>\n",
    "### Get deep features\n",
    "[BackToSection](#generate_deep_features_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2720, 128])\n",
      "torch.Size([136, 20, 128])\n"
     ]
    }
   ],
   "source": [
    "features_image = model(patches_image)\n",
    "print(features_image.shape)\n",
    "features_image = features_image.view(-1, 20, 128).cpu().data\n",
    "print(features_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file, with the name of features_CNN*.pth\n",
    "features_dir = \"image_description.pth\"\n",
    "torch.save(features_image, features_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([680, 128])\n",
      "torch.Size([34, 20, 128])\n"
     ]
    }
   ],
   "source": [
    "features_query = model(patches_query)\n",
    "print(features_query.shape)\n",
    "features_query = features_query.view(-1, 20, 128).cpu().data\n",
    "print(features_query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file, with the name of features_CNN*.pth\n",
    "features_dir = \"query_description.pth\"\n",
    "torch.save(features_query, features_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack query and image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_des = torch.load(\"query_description.pth\")\n",
    "image_des = torch.load(\"image_description.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 20, 128])\n",
      "torch.Size([136, 20, 128])\n"
     ]
    }
   ],
   "source": [
    "print(query_des.shape)\n",
    "print(image_des.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([170, 20, 128])\n"
     ]
    }
   ],
   "source": [
    "features = torch.cat([query_des, image_des], dim=0)\n",
    "print(features.shape)\n",
    "torch.save(features, \"features.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
