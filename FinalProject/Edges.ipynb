{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat.2718.jpg',\n",
       " 'dog.1753.jpg',\n",
       " 'human616.jpg',\n",
       " 'cat.1211.jpg',\n",
       " 'dog.775.jpg',\n",
       " 'human1,666.jpg',\n",
       " 'human1,100.jpg',\n",
       " 'cat.1577.jpg',\n",
       " 'human170.jpg',\n",
       " 'cat.952.jpg',\n",
       " 'dog.1035.jpg',\n",
       " 'cat.946.jpg',\n",
       " 'dog.1021.jpg',\n",
       " 'human1,114.jpg',\n",
       " 'cat.1563.jpg',\n",
       " 'human164.jpg',\n",
       " 'dog.2528.jpg',\n",
       " 'human2,969.jpg',\n",
       " 'human602.jpg',\n",
       " 'dog.761.jpg',\n",
       " 'cat.1205.jpg',\n",
       " 'human1,672.jpg',\n",
       " 'dog.1747.jpg',\n",
       " 'human2,941.jpg',\n",
       " 'dog.991.jpg',\n",
       " 'dog.2266.jpg',\n",
       " 'human1,882.jpg',\n",
       " 'human2,799.jpg',\n",
       " 'dog.749.jpg',\n",
       " 'cat.2724.jpg',\n",
       " 'dog.1009.jpg',\n",
       " 'cat.2042.jpg',\n",
       " 'dog.2500.jpg',\n",
       " 'human1,128.jpg',\n",
       " 'human158.jpg',\n",
       " 'dog.2514.jpg',\n",
       " 'cat.2056.jpg',\n",
       " 'cat.2730.jpg',\n",
       " 'dog.985.jpg',\n",
       " 'human2,955.jpg',\n",
       " 'dog.2272.jpg',\n",
       " 'human1,896.jpg',\n",
       " 'cat.1239.jpg',\n",
       " 'human2,766.jpg',\n",
       " 'cat.6.jpg',\n",
       " 'dog.2299.jpg',\n",
       " 'dog.1790.jpg',\n",
       " 'cat.2903.jpg',\n",
       " 'dog.1948.jpg',\n",
       " 'cat.749.jpg',\n",
       " 'cat.991.jpg',\n",
       " 'human2,000.jpg',\n",
       " 'human2,014.jpg',\n",
       " 'cat.985.jpg',\n",
       " 'dog.1784.jpg',\n",
       " 'cat.2917.jpg',\n",
       " 'human2,772.jpg',\n",
       " 'human819.jpg',\n",
       " 'human1,869.jpg',\n",
       " 'dog.1974.jpg',\n",
       " 'human831.jpg',\n",
       " 'human1,699.jpg',\n",
       " 'dog.952.jpg',\n",
       " 'human2,982.jpg',\n",
       " 'human1,841.jpg',\n",
       " 'cat.1588.jpg',\n",
       " 'cat.2081.jpg',\n",
       " 'cat.775.jpg',\n",
       " 'cat.761.jpg',\n",
       " 'cat.2095.jpg',\n",
       " 'human2,028.jpg',\n",
       " 'human825.jpg',\n",
       " 'human2,996.jpg',\n",
       " 'dog.946.jpg',\n",
       " 'human1,855.jpg',\n",
       " 'dog.1960.jpg',\n",
       " 'cat.588.jpg',\n",
       " 'dog.1237.jpg',\n",
       " 'human372.jpg',\n",
       " 'cat.1775.jpg',\n",
       " 'dog.211.jpg',\n",
       " 'human1,302.jpg',\n",
       " 'human1,464.jpg',\n",
       " 'dog.577.jpg',\n",
       " 'cat.1013.jpg',\n",
       " 'human414.jpg',\n",
       " 'dog.2058.jpg',\n",
       " 'dog.1551.jpg',\n",
       " 'dog.1545.jpg',\n",
       " 'human1,470.jpg',\n",
       " 'cat.1007.jpg',\n",
       " 'dog.563.jpg',\n",
       " 'human400.jpg',\n",
       " 'human366.jpg',\n",
       " 'dog.205.jpg',\n",
       " 'cat.1761.jpg',\n",
       " 'human1,316.jpg',\n",
       " 'cat.2268.jpg',\n",
       " 'dog.1223.jpg',\n",
       " 'cat.1991.jpg',\n",
       " 'dog.2702.jpg',\n",
       " 'cat.1749.jpg',\n",
       " 'cat.2240.jpg',\n",
       " 'cat.2526.jpg',\n",
       " 'human1,458.jpg',\n",
       " 'human428.jpg',\n",
       " 'dog.2064.jpg',\n",
       " 'dog.2070.jpg',\n",
       " 'dog.1579.jpg',\n",
       " 'cat.2532.jpg',\n",
       " 'cat.2254.jpg',\n",
       " 'cat.1985.jpg',\n",
       " 'dog.2716.jpg',\n",
       " 'dog.239.jpg',\n",
       " 'human2,202.jpg',\n",
       " 'dog.2925.jpg',\n",
       " 'dog.1592.jpg',\n",
       " 'human2,564.jpg',\n",
       " 'human2,570.jpg',\n",
       " 'cat.239.jpg',\n",
       " 'dog.1586.jpg',\n",
       " 'human2,216.jpg',\n",
       " 'dog.2931.jpg',\n",
       " 'human59.jpg',\n",
       " 'cat.2283.jpg',\n",
       " 'cat.577.jpg',\n",
       " 'dog.2919.jpg',\n",
       " 'human71.jpg',\n",
       " 'cat.1952.jpg',\n",
       " 'human2,558.jpg',\n",
       " 'dog.588.jpg',\n",
       " 'cat.211.jpg',\n",
       " 'cat.205.jpg',\n",
       " 'human65.jpg',\n",
       " 'cat.1946.jpg',\n",
       " 'human399.jpg',\n",
       " 'cat.563.jpg',\n",
       " 'cat.2297.jpg',\n",
       " 'dog.1343.jpg',\n",
       " 'cat.2308.jpg',\n",
       " 'dog.2892.jpg',\n",
       " 'human1,276.jpg',\n",
       " 'dog.365.jpg',\n",
       " 'cat.1601.jpg',\n",
       " 'human206.jpg',\n",
       " 'human560.jpg',\n",
       " 'cat.1167.jpg',\n",
       " 'dog.403.jpg',\n",
       " 'human1,510.jpg',\n",
       " 'dog.1425.jpg',\n",
       " 'dog.1431.jpg',\n",
       " 'human574.jpg',\n",
       " 'dog.2138.jpg',\n",
       " 'dog.417.jpg',\n",
       " 'cat.1173.jpg',\n",
       " 'human1,504.jpg',\n",
       " 'dog.2886.jpg',\n",
       " 'human1,262.jpg',\n",
       " 'cat.1615.jpg',\n",
       " 'dog.371.jpg',\n",
       " 'human212.jpg',\n",
       " 'dog.1357.jpg',\n",
       " 'human2,389.jpg',\n",
       " 'dog.359.jpg',\n",
       " 'dog.2676.jpg',\n",
       " 'cat.2334.jpg',\n",
       " 'cat.2452.jpg',\n",
       " 'dog.1419.jpg',\n",
       " 'dog.2110.jpg',\n",
       " 'human548.jpg',\n",
       " 'dog.2104.jpg',\n",
       " 'human1,538.jpg',\n",
       " 'cat.2446.jpg',\n",
       " 'cat.2320.jpg',\n",
       " 'cat.1629.jpg',\n",
       " 'dog.2662.jpg',\n",
       " 'dog.2689.jpg',\n",
       " 'dog.2851.jpg',\n",
       " 'human2,376.jpg',\n",
       " 'dog.1380.jpg',\n",
       " 'cat.359.jpg',\n",
       " 'human2,410.jpg',\n",
       " 'human2,404.jpg',\n",
       " 'dog.1394.jpg',\n",
       " 'dog.2845.jpg',\n",
       " 'human2,362.jpg',\n",
       " 'cat.403.jpg',\n",
       " 'cat.1826.jpg',\n",
       " 'human1,289.jpg',\n",
       " 'cat.1198.jpg',\n",
       " 'cat.365.jpg',\n",
       " 'cat.2491.jpg',\n",
       " 'cat.2485.jpg',\n",
       " 'cat.371.jpg',\n",
       " 'human2,438.jpg',\n",
       " 'cat.1832.jpg',\n",
       " 'dog.2879.jpg',\n",
       " 'cat.417.jpg',\n",
       " 'dog.1627.jpg',\n",
       " 'cat.198.jpg',\n",
       " 'human1,712.jpg',\n",
       " 'dog.601.jpg',\n",
       " 'cat.1365.jpg',\n",
       " 'human762.jpg',\n",
       " 'human2,809.jpg',\n",
       " 'dog.2448.jpg',\n",
       " 'cat.1403.jpg',\n",
       " 'dog.167.jpg',\n",
       " 'human1,074.jpg',\n",
       " 'dog.1141.jpg',\n",
       " 'cat.826.jpg',\n",
       " 'dog.1155.jpg',\n",
       " 'cat.832.jpg',\n",
       " 'dog.173.jpg',\n",
       " 'cat.1417.jpg',\n",
       " 'human1,060.jpg',\n",
       " 'human1,706.jpg',\n",
       " 'cat.1371.jpg',\n",
       " 'dog.615.jpg',\n",
       " 'human776.jpg',\n",
       " 'dog.1633.jpg',\n",
       " 'cat.2678.jpg',\n",
       " 'human986.jpg',\n",
       " 'cat.1359.jpg',\n",
       " 'dog.2312.jpg',\n",
       " 'human2,835.jpg',\n",
       " 'cat.2888.jpg',\n",
       " 'cat.2650.jpg',\n",
       " 'dog.36.jpg',\n",
       " 'cat.2136.jpg',\n",
       " 'dog.2474.jpg',\n",
       " 'human1,048.jpg',\n",
       " 'dog.2460.jpg',\n",
       " 'cat.2122.jpg',\n",
       " 'dog.1169.jpg',\n",
       " 'cat.2644.jpg',\n",
       " 'dog.22.jpg',\n",
       " 'human992.jpg',\n",
       " 'dog.629.jpg',\n",
       " 'dog.2306.jpg',\n",
       " 'human2,821.jpg',\n",
       " 'human1,909.jpg',\n",
       " 'human979.jpg',\n",
       " 'human2,612.jpg',\n",
       " 'cat.30.jpg',\n",
       " 'cat.2877.jpg',\n",
       " 'dog.1182.jpg',\n",
       " 'human2,174.jpg',\n",
       " 'human2,160.jpg',\n",
       " 'dog.1196.jpg',\n",
       " 'cat.629.jpg',\n",
       " 'cat.24.jpg',\n",
       " 'dog.1828.jpg',\n",
       " 'cat.2863.jpg',\n",
       " 'human2,606.jpg',\n",
       " 'cat.167.jpg',\n",
       " 'cat.2693.jpg',\n",
       " 'dog.1800.jpg',\n",
       " 'human1,935.jpg',\n",
       " 'dog.826.jpg',\n",
       " 'human945.jpg',\n",
       " 'human2,148.jpg',\n",
       " 'dog.198.jpg',\n",
       " 'cat.601.jpg',\n",
       " 'cat.615.jpg',\n",
       " 'human789.jpg',\n",
       " 'human1,921.jpg',\n",
       " 'dog.832.jpg',\n",
       " 'human951.jpg',\n",
       " 'cat.18.jpg',\n",
       " 'cat.2687.jpg',\n",
       " 'cat.173.jpg',\n",
       " 'dog.1814.jpg',\n",
       " 'cat.614.jpg',\n",
       " 'dog.1815.jpg',\n",
       " 'cat.172.jpg',\n",
       " 'cat.2686.jpg',\n",
       " 'cat.19.jpg',\n",
       " 'human950.jpg',\n",
       " 'dog.833.jpg',\n",
       " 'human1,920.jpg',\n",
       " 'human788.jpg',\n",
       " 'human944.jpg',\n",
       " 'dog.827.jpg',\n",
       " 'human1,934.jpg',\n",
       " 'dog.1801.jpg',\n",
       " 'cat.2692.jpg',\n",
       " 'cat.166.jpg',\n",
       " 'cat.600.jpg',\n",
       " 'human2,149.jpg',\n",
       " 'dog.199.jpg',\n",
       " 'cat.628.jpg',\n",
       " 'dog.1197.jpg',\n",
       " 'human2,161.jpg',\n",
       " 'human2,607.jpg',\n",
       " 'cat.2862.jpg',\n",
       " 'dog.1829.jpg',\n",
       " 'cat.25.jpg',\n",
       " 'cat.2876.jpg',\n",
       " 'cat.31.jpg',\n",
       " 'human2,613.jpg',\n",
       " 'human978.jpg',\n",
       " 'human1,908.jpg',\n",
       " 'human2,175.jpg',\n",
       " 'dog.1183.jpg',\n",
       " 'dog.1168.jpg',\n",
       " 'cat.2123.jpg',\n",
       " 'dog.2461.jpg',\n",
       " 'human2,820.jpg',\n",
       " 'dog.2307.jpg',\n",
       " 'dog.628.jpg',\n",
       " 'human993.jpg',\n",
       " 'dog.23.jpg',\n",
       " 'cat.2645.jpg',\n",
       " 'dog.37.jpg',\n",
       " 'cat.2651.jpg',\n",
       " 'cat.2889.jpg',\n",
       " 'human2,834.jpg',\n",
       " 'dog.2313.jpg',\n",
       " 'cat.1358.jpg',\n",
       " 'human987.jpg',\n",
       " 'human1,049.jpg',\n",
       " 'dog.2475.jpg',\n",
       " 'cat.2137.jpg',\n",
       " 'human1,061.jpg',\n",
       " 'cat.1416.jpg',\n",
       " 'dog.172.jpg',\n",
       " 'cat.833.jpg',\n",
       " 'dog.1154.jpg',\n",
       " 'cat.2679.jpg',\n",
       " 'dog.1632.jpg',\n",
       " 'human777.jpg',\n",
       " 'dog.614.jpg',\n",
       " 'cat.1370.jpg',\n",
       " 'human1,707.jpg',\n",
       " 'human2,808.jpg',\n",
       " 'human763.jpg',\n",
       " 'cat.1364.jpg',\n",
       " 'dog.600.jpg',\n",
       " 'human1,713.jpg',\n",
       " 'cat.199.jpg',\n",
       " 'dog.1626.jpg',\n",
       " 'cat.827.jpg',\n",
       " 'dog.1140.jpg',\n",
       " 'human1,075.jpg',\n",
       " 'dog.166.jpg',\n",
       " 'cat.1402.jpg',\n",
       " 'dog.2449.jpg',\n",
       " 'human2,439.jpg',\n",
       " 'cat.370.jpg',\n",
       " 'cat.2484.jpg',\n",
       " 'cat.416.jpg',\n",
       " 'dog.2878.jpg',\n",
       " 'cat.1833.jpg',\n",
       " 'human1,288.jpg',\n",
       " 'cat.1827.jpg',\n",
       " 'cat.402.jpg',\n",
       " 'cat.2490.jpg',\n",
       " 'cat.364.jpg',\n",
       " 'cat.1199.jpg',\n",
       " 'human2,405.jpg',\n",
       " 'human2,363.jpg',\n",
       " 'dog.2844.jpg',\n",
       " 'dog.1395.jpg',\n",
       " 'dog.1381.jpg',\n",
       " 'human2,377.jpg',\n",
       " 'dog.2850.jpg',\n",
       " 'dog.2688.jpg',\n",
       " 'human2,411.jpg',\n",
       " 'cat.358.jpg',\n",
       " 'cat.2447.jpg',\n",
       " 'human1,539.jpg',\n",
       " 'human549.jpg',\n",
       " 'dog.2105.jpg',\n",
       " 'dog.2663.jpg',\n",
       " 'cat.1628.jpg',\n",
       " 'cat.2321.jpg',\n",
       " 'cat.2335.jpg',\n",
       " 'dog.2677.jpg',\n",
       " 'human2,388.jpg',\n",
       " 'dog.358.jpg',\n",
       " 'dog.2111.jpg',\n",
       " 'dog.1418.jpg',\n",
       " 'cat.2453.jpg',\n",
       " 'human1,505.jpg',\n",
       " 'cat.1172.jpg',\n",
       " 'dog.416.jpg',\n",
       " 'human575.jpg',\n",
       " 'dog.2139.jpg',\n",
       " 'dog.1430.jpg',\n",
       " 'dog.1356.jpg',\n",
       " 'human213.jpg',\n",
       " 'dog.370.jpg',\n",
       " 'cat.1614.jpg',\n",
       " 'human1,263.jpg',\n",
       " 'dog.2887.jpg',\n",
       " 'human207.jpg',\n",
       " 'cat.1600.jpg',\n",
       " 'dog.364.jpg',\n",
       " 'human1,277.jpg',\n",
       " 'dog.2893.jpg',\n",
       " 'cat.2309.jpg',\n",
       " 'dog.1342.jpg',\n",
       " 'dog.1424.jpg',\n",
       " 'human1,511.jpg',\n",
       " 'dog.402.jpg',\n",
       " 'cat.1166.jpg',\n",
       " 'human561.jpg',\n",
       " 'cat.204.jpg',\n",
       " 'cat.2296.jpg',\n",
       " 'cat.562.jpg',\n",
       " 'human398.jpg',\n",
       " 'cat.1947.jpg',\n",
       " 'human64.jpg',\n",
       " 'cat.1953.jpg',\n",
       " 'human70.jpg',\n",
       " 'dog.2918.jpg',\n",
       " 'cat.576.jpg',\n",
       " 'cat.2282.jpg',\n",
       " 'cat.210.jpg',\n",
       " 'human2,559.jpg',\n",
       " 'dog.589.jpg',\n",
       " 'dog.1587.jpg',\n",
       " 'cat.238.jpg',\n",
       " 'human2,571.jpg',\n",
       " 'human58.jpg',\n",
       " 'dog.2930.jpg',\n",
       " 'human2,217.jpg',\n",
       " 'dog.2924.jpg',\n",
       " 'human2,203.jpg',\n",
       " 'human2,565.jpg',\n",
       " 'dog.1593.jpg',\n",
       " 'cat.2533.jpg',\n",
       " 'dog.1578.jpg',\n",
       " 'dog.2071.jpg',\n",
       " 'dog.238.jpg',\n",
       " 'dog.2717.jpg',\n",
       " 'cat.1984.jpg',\n",
       " 'cat.2255.jpg',\n",
       " 'cat.2241.jpg',\n",
       " 'cat.1748.jpg',\n",
       " 'dog.2703.jpg',\n",
       " 'cat.1990.jpg',\n",
       " 'human429.jpg',\n",
       " 'dog.2065.jpg',\n",
       " 'human1,459.jpg',\n",
       " 'cat.2527.jpg',\n",
       " 'human401.jpg',\n",
       " 'dog.562.jpg',\n",
       " 'cat.1006.jpg',\n",
       " 'human1,471.jpg',\n",
       " 'dog.1544.jpg',\n",
       " 'dog.1222.jpg',\n",
       " 'cat.2269.jpg',\n",
       " 'human1,317.jpg',\n",
       " 'cat.1760.jpg',\n",
       " 'dog.204.jpg',\n",
       " 'human367.jpg',\n",
       " 'human1,303.jpg',\n",
       " 'dog.210.jpg',\n",
       " 'cat.1774.jpg',\n",
       " 'human373.jpg',\n",
       " 'dog.1236.jpg',\n",
       " 'cat.589.jpg',\n",
       " 'dog.1550.jpg',\n",
       " 'human415.jpg',\n",
       " 'dog.2059.jpg',\n",
       " 'cat.1012.jpg',\n",
       " 'dog.576.jpg',\n",
       " 'human1,465.jpg',\n",
       " 'human2,029.jpg',\n",
       " 'cat.2094.jpg',\n",
       " 'cat.760.jpg',\n",
       " 'dog.1961.jpg',\n",
       " 'dog.947.jpg',\n",
       " 'human1,854.jpg',\n",
       " 'human2,997.jpg',\n",
       " 'human824.jpg',\n",
       " 'human1,840.jpg',\n",
       " 'dog.953.jpg',\n",
       " 'human2,983.jpg',\n",
       " 'human1,698.jpg',\n",
       " 'human830.jpg',\n",
       " 'dog.1975.jpg',\n",
       " 'cat.774.jpg',\n",
       " 'cat.2080.jpg',\n",
       " 'cat.1589.jpg',\n",
       " 'cat.984.jpg',\n",
       " 'human2,015.jpg',\n",
       " 'human1,868.jpg',\n",
       " 'human818.jpg',\n",
       " 'human2,773.jpg',\n",
       " 'cat.2916.jpg',\n",
       " 'dog.1785.jpg',\n",
       " 'dog.1949.jpg',\n",
       " 'cat.2902.jpg',\n",
       " 'dog.1791.jpg',\n",
       " 'dog.2298.jpg',\n",
       " 'cat.7.jpg',\n",
       " 'human2,767.jpg',\n",
       " 'human2,001.jpg',\n",
       " 'cat.990.jpg',\n",
       " 'cat.748.jpg',\n",
       " 'cat.2057.jpg',\n",
       " 'human159.jpg',\n",
       " 'dog.2515.jpg',\n",
       " 'human1,129.jpg',\n",
       " 'cat.1238.jpg',\n",
       " 'human1,897.jpg',\n",
       " 'dog.2273.jpg',\n",
       " 'dog.984.jpg',\n",
       " 'human2,954.jpg',\n",
       " 'cat.2731.jpg',\n",
       " 'cat.2725.jpg',\n",
       " 'human2,798.jpg',\n",
       " 'dog.748.jpg',\n",
       " 'human1,883.jpg',\n",
       " 'dog.2267.jpg',\n",
       " 'human2,940.jpg',\n",
       " 'dog.990.jpg',\n",
       " 'dog.2501.jpg',\n",
       " 'cat.2043.jpg',\n",
       " 'dog.1008.jpg',\n",
       " 'human165.jpg',\n",
       " 'dog.2529.jpg',\n",
       " 'cat.1562.jpg',\n",
       " 'human1,115.jpg',\n",
       " 'dog.1020.jpg',\n",
       " 'cat.947.jpg',\n",
       " 'dog.1746.jpg',\n",
       " 'human1,673.jpg',\n",
       " 'cat.1204.jpg',\n",
       " 'dog.760.jpg',\n",
       " 'human603.jpg',\n",
       " 'human2,968.jpg',\n",
       " 'human1,667.jpg',\n",
       " 'dog.774.jpg',\n",
       " 'cat.1210.jpg',\n",
       " 'human617.jpg',\n",
       " 'dog.1752.jpg',\n",
       " 'cat.2719.jpg',\n",
       " 'dog.1034.jpg',\n",
       " 'cat.953.jpg',\n",
       " 'human171.jpg',\n",
       " 'cat.1576.jpg',\n",
       " 'human1,101.jpg',\n",
       " 'human601.jpg',\n",
       " 'dog.762.jpg',\n",
       " 'cat.1206.jpg',\n",
       " 'human1,671.jpg',\n",
       " 'dog.1744.jpg',\n",
       " 'cat.945.jpg',\n",
       " 'dog.1022.jpg',\n",
       " 'cat.2069.jpg',\n",
       " 'human1,117.jpg',\n",
       " 'cat.1560.jpg',\n",
       " 'human167.jpg',\n",
       " 'human1,103.jpg',\n",
       " 'cat.1574.jpg',\n",
       " 'human173.jpg',\n",
       " 'cat.951.jpg',\n",
       " 'dog.1036.jpg',\n",
       " 'cat.789.jpg',\n",
       " 'dog.1988.jpg',\n",
       " 'dog.1750.jpg',\n",
       " 'human615.jpg',\n",
       " 'dog.2259.jpg',\n",
       " 'cat.1212.jpg',\n",
       " 'dog.776.jpg',\n",
       " 'human1,665.jpg',\n",
       " 'cat.2733.jpg',\n",
       " 'dog.1778.jpg',\n",
       " 'human2,956.jpg',\n",
       " 'dog.986.jpg',\n",
       " 'human1,895.jpg',\n",
       " 'dog.2271.jpg',\n",
       " 'dog.2517.jpg',\n",
       " 'cat.979.jpg',\n",
       " 'cat.2055.jpg',\n",
       " 'cat.2041.jpg',\n",
       " 'cat.1548.jpg',\n",
       " 'dog.2503.jpg',\n",
       " 'dog.992.jpg',\n",
       " 'human2,942.jpg',\n",
       " 'human1,881.jpg',\n",
       " 'human629.jpg',\n",
       " 'dog.2265.jpg',\n",
       " 'human1,659.jpg',\n",
       " 'cat.2727.jpg',\n",
       " 'dog.1787.jpg',\n",
       " 'cat.2914.jpg',\n",
       " 'human2,771.jpg',\n",
       " 'dog.979.jpg',\n",
       " 'human2,017.jpg',\n",
       " 'cat.986.jpg',\n",
       " 'cat.992.jpg',\n",
       " 'human2,003.jpg',\n",
       " 'human2,765.jpg',\n",
       " 'cat.5.jpg',\n",
       " 'dog.1793.jpg',\n",
       " 'cat.2900.jpg',\n",
       " 'human826.jpg',\n",
       " 'dog.945.jpg',\n",
       " 'human2,995.jpg',\n",
       " 'human1,856.jpg',\n",
       " 'cat.2928.jpg',\n",
       " 'dog.1963.jpg',\n",
       " 'cat.762.jpg',\n",
       " 'cat.2096.jpg',\n",
       " 'human198.jpg',\n",
       " 'cat.2082.jpg',\n",
       " 'cat.776.jpg',\n",
       " 'dog.1977.jpg',\n",
       " 'human2,759.jpg',\n",
       " 'dog.789.jpg',\n",
       " 'human832.jpg',\n",
       " 'human2,981.jpg',\n",
       " 'dog.951.jpg',\n",
       " 'human1,842.jpg',\n",
       " 'human99.jpg',\n",
       " 'human365.jpg',\n",
       " 'dog.2729.jpg',\n",
       " 'dog.206.jpg',\n",
       " 'cat.1762.jpg',\n",
       " 'human1,315.jpg',\n",
       " 'dog.1220.jpg',\n",
       " 'dog.1546.jpg',\n",
       " 'human1,473.jpg',\n",
       " 'cat.1004.jpg',\n",
       " 'dog.560.jpg',\n",
       " 'human403.jpg',\n",
       " 'human1,467.jpg',\n",
       " 'dog.574.jpg',\n",
       " 'cat.1010.jpg',\n",
       " 'human417.jpg',\n",
       " 'dog.1552.jpg',\n",
       " 'cat.2519.jpg',\n",
       " 'dog.1234.jpg',\n",
       " 'human371.jpg',\n",
       " 'cat.1776.jpg',\n",
       " 'dog.212.jpg',\n",
       " 'human1,301.jpg',\n",
       " 'cat.2257.jpg',\n",
       " 'cat.1986.jpg',\n",
       " 'human359.jpg',\n",
       " 'dog.2715.jpg',\n",
       " 'human1,329.jpg',\n",
       " 'cat.1038.jpg',\n",
       " 'dog.2073.jpg',\n",
       " 'cat.2531.jpg',\n",
       " 'cat.2525.jpg',\n",
       " 'human2,598.jpg',\n",
       " 'dog.548.jpg',\n",
       " 'dog.2067.jpg',\n",
       " 'cat.1992.jpg',\n",
       " 'dog.2701.jpg',\n",
       " 'cat.2243.jpg',\n",
       " 'dog.1208.jpg',\n",
       " 'human2,215.jpg',\n",
       " 'dog.2932.jpg',\n",
       " 'cat.1979.jpg',\n",
       " 'human2,573.jpg',\n",
       " 'dog.1585.jpg',\n",
       " 'dog.1591.jpg',\n",
       " 'dog.2098.jpg',\n",
       " 'human2,567.jpg',\n",
       " 'human2,201.jpg',\n",
       " 'dog.2926.jpg',\n",
       " 'cat.548.jpg',\n",
       " 'human2,229.jpg',\n",
       " 'cat.1945.jpg',\n",
       " 'human66.jpg',\n",
       " 'cat.560.jpg',\n",
       " 'cat.2294.jpg',\n",
       " 'cat.206.jpg',\n",
       " 'human1,498.jpg',\n",
       " 'cat.212.jpg',\n",
       " 'cat.2280.jpg',\n",
       " 'cat.574.jpg',\n",
       " 'cat.1789.jpg',\n",
       " 'cat.1951.jpg',\n",
       " 'human72.jpg',\n",
       " 'human1,261.jpg',\n",
       " 'dog.2885.jpg',\n",
       " 'cat.1616.jpg',\n",
       " 'dog.372.jpg',\n",
       " 'human211.jpg',\n",
       " 'dog.1354.jpg',\n",
       " 'cat.2479.jpg',\n",
       " 'dog.1432.jpg',\n",
       " 'human577.jpg',\n",
       " 'dog.414.jpg',\n",
       " 'cat.1170.jpg',\n",
       " 'human1,507.jpg',\n",
       " 'human563.jpg',\n",
       " 'cat.1164.jpg',\n",
       " 'dog.400.jpg',\n",
       " 'human1,513.jpg',\n",
       " 'cat.399.jpg',\n",
       " 'dog.1426.jpg',\n",
       " 'dog.1340.jpg',\n",
       " 'human1,275.jpg',\n",
       " 'dog.2891.jpg',\n",
       " 'dog.366.jpg',\n",
       " 'cat.1602.jpg',\n",
       " 'human205.jpg',\n",
       " 'dog.2649.jpg',\n",
       " 'dog.1368.jpg',\n",
       " 'cat.2323.jpg',\n",
       " 'dog.2661.jpg',\n",
       " 'dog.2107.jpg',\n",
       " 'dog.428.jpg',\n",
       " 'cat.2445.jpg',\n",
       " 'cat.2451.jpg',\n",
       " 'dog.2113.jpg',\n",
       " 'cat.1158.jpg',\n",
       " 'human1,249.jpg',\n",
       " 'human239.jpg',\n",
       " 'dog.2675.jpg',\n",
       " 'cat.2337.jpg',\n",
       " 'cat.428.jpg',\n",
       " 'dog.1397.jpg',\n",
       " 'dog.2846.jpg',\n",
       " 'human2,361.jpg',\n",
       " 'human2,407.jpg',\n",
       " 'human2,413.jpg',\n",
       " 'cat.1819.jpg',\n",
       " 'dog.2852.jpg',\n",
       " 'human2,375.jpg',\n",
       " 'dog.1383.jpg',\n",
       " 'cat.1831.jpg',\n",
       " 'cat.414.jpg',\n",
       " 'cat.2486.jpg',\n",
       " 'cat.372.jpg',\n",
       " 'human588.jpg',\n",
       " 'cat.366.jpg',\n",
       " 'cat.2492.jpg',\n",
       " 'cat.400.jpg',\n",
       " 'cat.1825.jpg',\n",
       " 'human2,349.jpg',\n",
       " 'dog.399.jpg',\n",
       " 'human1,705.jpg',\n",
       " 'cat.1372.jpg',\n",
       " 'dog.616.jpg',\n",
       " 'human775.jpg',\n",
       " 'dog.2339.jpg',\n",
       " 'dog.1630.jpg',\n",
       " 'dog.1156.jpg',\n",
       " 'cat.831.jpg',\n",
       " 'dog.170.jpg',\n",
       " 'cat.1414.jpg',\n",
       " 'human1,063.jpg',\n",
       " 'cat.1400.jpg',\n",
       " 'dog.164.jpg',\n",
       " 'human1,077.jpg',\n",
       " 'cat.2109.jpg',\n",
       " 'dog.1142.jpg',\n",
       " 'cat.825.jpg',\n",
       " 'dog.1624.jpg',\n",
       " 'human1,711.jpg',\n",
       " 'dog.602.jpg',\n",
       " 'cat.1366.jpg',\n",
       " 'human761.jpg',\n",
       " 'cat.2647.jpg',\n",
       " 'dog.21.jpg',\n",
       " 'human1,739.jpg',\n",
       " 'human991.jpg',\n",
       " 'human749.jpg',\n",
       " 'dog.2305.jpg',\n",
       " 'human2,822.jpg',\n",
       " 'dog.2463.jpg',\n",
       " 'cat.1428.jpg',\n",
       " 'cat.2121.jpg',\n",
       " 'cat.2135.jpg',\n",
       " 'cat.819.jpg',\n",
       " 'dog.2477.jpg',\n",
       " 'human2,188.jpg',\n",
       " 'dog.158.jpg',\n",
       " 'human985.jpg',\n",
       " 'dog.2311.jpg',\n",
       " 'human2,836.jpg',\n",
       " 'dog.1618.jpg',\n",
       " 'cat.2653.jpg',\n",
       " 'dog.35.jpg',\n",
       " 'cat.27.jpg',\n",
       " 'cat.2860.jpg',\n",
       " 'human2,605.jpg',\n",
       " 'human2,163.jpg',\n",
       " 'dog.1195.jpg',\n",
       " 'dog.1181.jpg',\n",
       " 'dog.2488.jpg',\n",
       " 'human2,177.jpg',\n",
       " 'dog.819.jpg',\n",
       " 'human2,611.jpg',\n",
       " 'cat.33.jpg',\n",
       " 'cat.158.jpg',\n",
       " 'cat.2874.jpg',\n",
       " 'human1,922.jpg',\n",
       " 'dog.831.jpg',\n",
       " 'human952.jpg',\n",
       " 'human2,639.jpg',\n",
       " 'cat.2684.jpg',\n",
       " 'cat.170.jpg',\n",
       " 'dog.1817.jpg',\n",
       " 'cat.616.jpg',\n",
       " 'human1,088.jpg',\n",
       " 'cat.602.jpg',\n",
       " 'cat.164.jpg',\n",
       " 'cat.2690.jpg',\n",
       " 'dog.1803.jpg',\n",
       " 'cat.2848.jpg',\n",
       " 'human1,936.jpg',\n",
       " 'dog.825.jpg',\n",
       " 'human946.jpg',\n",
       " 'cat.1399.jpg',\n",
       " 'cat.603.jpg',\n",
       " 'human1,089.jpg',\n",
       " 'cat.1398.jpg',\n",
       " 'human947.jpg',\n",
       " 'dog.824.jpg',\n",
       " 'human1,937.jpg',\n",
       " 'cat.2849.jpg',\n",
       " 'dog.1802.jpg',\n",
       " 'cat.2691.jpg',\n",
       " 'cat.165.jpg',\n",
       " 'dog.1816.jpg',\n",
       " 'cat.171.jpg',\n",
       " 'cat.2685.jpg',\n",
       " 'human2,638.jpg',\n",
       " 'human953.jpg',\n",
       " 'dog.830.jpg',\n",
       " 'human1,923.jpg',\n",
       " 'cat.617.jpg',\n",
       " 'dog.2489.jpg',\n",
       " 'human2,176.jpg',\n",
       " 'dog.1180.jpg',\n",
       " 'cat.2875.jpg',\n",
       " 'cat.159.jpg',\n",
       " 'cat.32.jpg',\n",
       " 'human2,610.jpg',\n",
       " 'dog.818.jpg',\n",
       " 'human2,604.jpg',\n",
       " 'cat.2861.jpg',\n",
       " 'cat.26.jpg',\n",
       " 'dog.1194.jpg',\n",
       " 'human2,162.jpg',\n",
       " 'human2,189.jpg',\n",
       " 'dog.159.jpg',\n",
       " 'dog.2476.jpg',\n",
       " 'cat.818.jpg',\n",
       " 'cat.2134.jpg',\n",
       " 'dog.34.jpg',\n",
       " 'cat.2652.jpg',\n",
       " 'dog.1619.jpg',\n",
       " 'human2,837.jpg',\n",
       " 'dog.2310.jpg',\n",
       " 'human984.jpg',\n",
       " 'human2,823.jpg',\n",
       " 'human748.jpg',\n",
       " 'dog.2304.jpg',\n",
       " 'human990.jpg',\n",
       " 'human1,738.jpg',\n",
       " 'dog.20.jpg',\n",
       " 'cat.2646.jpg',\n",
       " 'cat.2120.jpg',\n",
       " 'cat.1429.jpg',\n",
       " 'dog.2462.jpg',\n",
       " 'cat.824.jpg',\n",
       " 'dog.1143.jpg',\n",
       " 'cat.2108.jpg',\n",
       " 'human1,076.jpg',\n",
       " 'dog.165.jpg',\n",
       " 'cat.1401.jpg',\n",
       " 'human760.jpg',\n",
       " 'cat.1367.jpg',\n",
       " 'dog.603.jpg',\n",
       " 'human1,710.jpg',\n",
       " 'dog.1625.jpg',\n",
       " 'dog.1631.jpg',\n",
       " 'human774.jpg',\n",
       " 'dog.2338.jpg',\n",
       " 'dog.617.jpg',\n",
       " 'cat.1373.jpg',\n",
       " 'human1,704.jpg',\n",
       " 'human1,062.jpg',\n",
       " 'cat.1415.jpg',\n",
       " 'dog.171.jpg',\n",
       " 'cat.830.jpg',\n",
       " 'dog.1157.jpg',\n",
       " 'cat.2493.jpg',\n",
       " 'cat.367.jpg',\n",
       " 'human2,348.jpg',\n",
       " 'dog.398.jpg',\n",
       " 'cat.1824.jpg',\n",
       " 'cat.401.jpg',\n",
       " 'cat.415.jpg',\n",
       " 'cat.1830.jpg',\n",
       " 'human589.jpg',\n",
       " 'cat.373.jpg',\n",
       " 'cat.2487.jpg',\n",
       " 'human2,412.jpg',\n",
       " 'dog.1382.jpg',\n",
       " 'human2,374.jpg',\n",
       " 'dog.2853.jpg',\n",
       " 'cat.1818.jpg',\n",
       " 'human2,360.jpg',\n",
       " 'dog.2847.jpg',\n",
       " 'dog.1396.jpg',\n",
       " 'cat.429.jpg',\n",
       " 'human2,406.jpg',\n",
       " 'cat.1159.jpg',\n",
       " 'dog.2112.jpg',\n",
       " 'cat.2450.jpg',\n",
       " 'cat.2336.jpg',\n",
       " 'human238.jpg',\n",
       " 'dog.2674.jpg',\n",
       " 'human1,248.jpg',\n",
       " 'dog.2660.jpg',\n",
       " 'cat.2322.jpg',\n",
       " 'dog.1369.jpg',\n",
       " 'cat.2444.jpg',\n",
       " 'dog.429.jpg',\n",
       " 'dog.2106.jpg',\n",
       " 'dog.1427.jpg',\n",
       " 'cat.398.jpg',\n",
       " 'human1,512.jpg',\n",
       " 'dog.401.jpg',\n",
       " 'cat.1165.jpg',\n",
       " 'human562.jpg',\n",
       " 'human204.jpg',\n",
       " 'dog.2648.jpg',\n",
       " 'cat.1603.jpg',\n",
       " 'dog.367.jpg',\n",
       " 'dog.2890.jpg',\n",
       " 'human1,274.jpg',\n",
       " 'dog.1341.jpg',\n",
       " 'dog.1355.jpg',\n",
       " 'human210.jpg',\n",
       " 'dog.373.jpg',\n",
       " 'cat.1617.jpg',\n",
       " 'dog.2884.jpg',\n",
       " 'human1,260.jpg',\n",
       " 'human1,506.jpg',\n",
       " 'cat.1171.jpg',\n",
       " 'dog.415.jpg',\n",
       " 'human576.jpg',\n",
       " 'dog.1433.jpg',\n",
       " 'cat.2478.jpg',\n",
       " 'cat.213.jpg',\n",
       " 'human1,499.jpg',\n",
       " 'human73.jpg',\n",
       " 'cat.1950.jpg',\n",
       " 'cat.1788.jpg',\n",
       " 'cat.575.jpg',\n",
       " 'cat.2281.jpg',\n",
       " 'cat.2295.jpg',\n",
       " 'cat.561.jpg',\n",
       " 'human67.jpg',\n",
       " 'cat.1944.jpg',\n",
       " 'human2,228.jpg',\n",
       " 'cat.207.jpg',\n",
       " 'human2,566.jpg',\n",
       " 'dog.2099.jpg',\n",
       " 'dog.1590.jpg',\n",
       " 'cat.549.jpg',\n",
       " 'dog.2927.jpg',\n",
       " 'human2,200.jpg',\n",
       " 'cat.1978.jpg',\n",
       " 'dog.2933.jpg',\n",
       " 'human2,214.jpg',\n",
       " 'dog.1584.jpg',\n",
       " 'human2,572.jpg',\n",
       " 'dog.2066.jpg',\n",
       " 'human2,599.jpg',\n",
       " 'dog.549.jpg',\n",
       " 'cat.2524.jpg',\n",
       " 'dog.1209.jpg',\n",
       " 'cat.2242.jpg',\n",
       " 'dog.2700.jpg',\n",
       " 'cat.1993.jpg',\n",
       " 'human1,328.jpg',\n",
       " 'human358.jpg',\n",
       " 'dog.2714.jpg',\n",
       " 'cat.1987.jpg',\n",
       " 'cat.2256.jpg',\n",
       " 'cat.2530.jpg',\n",
       " 'dog.2072.jpg',\n",
       " 'cat.1039.jpg',\n",
       " 'cat.2518.jpg',\n",
       " 'dog.1553.jpg',\n",
       " 'human416.jpg',\n",
       " 'cat.1011.jpg',\n",
       " 'dog.575.jpg',\n",
       " 'human1,466.jpg',\n",
       " 'human1,300.jpg',\n",
       " 'dog.213.jpg',\n",
       " 'cat.1777.jpg',\n",
       " 'human370.jpg',\n",
       " 'dog.1235.jpg',\n",
       " 'dog.1221.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "train_images = os.listdir('../data/train')\n",
    "test_images = os.listdir('../data/test')\n",
    "\n",
    "print(len(train_images))\n",
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat.2718.jpg',\n",
       " 'dog.1753.jpg',\n",
       " 'human616.jpg',\n",
       " 'cat.1211.jpg',\n",
       " 'dog.775.jpg',\n",
       " 'human1,666.jpg',\n",
       " 'human1,100.jpg',\n",
       " 'cat.1577.jpg',\n",
       " 'human170.jpg',\n",
       " 'cat.952.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat.3406.jpg',\n",
       " 'human616.jpg',\n",
       " 'dog.3144.jpg',\n",
       " 'dog.3622.jpg',\n",
       " 'human170.jpg',\n",
       " 'cat.3360.jpg',\n",
       " 'cat.3374.jpg',\n",
       " 'dog.3636.jpg',\n",
       " 'human164.jpg',\n",
       " 'human602.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:07<00:00, 405.12it/s]\n"
     ]
    }
   ],
   "source": [
    "test_images_data = []\n",
    "\n",
    "for image in tqdm(test_images):\n",
    "    image_data = cv2.imread('../data/test/' + image)\n",
    "    \n",
    "    #Convert to GrayScale\n",
    "    gray = cv2.cvtColor(image_data, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #convert color from BGR to RGB\n",
    "    #image_data = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    image_data = cv2.resize(gray, (64, 64))\n",
    "    \n",
    "    #turn to only borders\n",
    "    image_data = cv2.Canny(image_data, 150, 150)\n",
    "    \n",
    "    test_images_data.append(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 64, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_data = np.array(test_images_data)\n",
    "test_images_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [00:21<00:00, 420.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images_data = []\n",
    "train_images_labels = []\n",
    "\n",
    "random.shuffle(train_images)\n",
    "\n",
    "for image in tqdm(train_images):\n",
    "    image_data = cv2.imread('../data/train/' + image)\n",
    "    \n",
    "    #Convert to GrayScale\n",
    "    gray = cv2.cvtColor(image_data, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #convert color from BGR to RGB\n",
    "    #image_data = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    image_data = cv2.resize(gray, (64, 64))\n",
    "    \n",
    "    #turn to only borders\n",
    "    image_data = cv2.Canny(image_data, 150, 150)\n",
    "    \n",
    "    train_images_data.append(image_data)\n",
    "    train_images_data.append(image_data[:, ::-1]) #flipped image\n",
    "    \n",
    "    \n",
    "    if image.startswith('cat'):\n",
    "#         train_images_labels.append(0)\n",
    "#         train_images_labels.append(0)\n",
    "        train_images_labels.append([0, 1, 0])\n",
    "        train_images_labels.append([0, 1, 0])\n",
    "    elif image.startswith('dog'):\n",
    "#         train_images_labels.append(1)\n",
    "#         train_images_labels.append(1)\n",
    "        train_images_labels.append([1, 0, 0])\n",
    "        train_images_labels.append([1, 0, 0])\n",
    "    else:\n",
    "#         train_images_labels.append(2)\n",
    "#         train_images_labels.append(2)  \n",
    "        train_images_labels.append([0, 0, 1])\n",
    "        train_images_labels.append([0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_data = np.array(train_images_data)\n",
    "train_images_labels = np.array(train_images_labels)\n",
    "\n",
    "train_images_data = train_images_data.reshape([-1, 64, 64, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "train_images_data_b = copy.deepcopy(train_images_data) \n",
    "train_images_labels_b = copy.deepcopy(train_images_labels)\n",
    "test_images_data = copy.deepcopy(test_images_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_data = train_images_data[:4500]\n",
    "train_images_labels = train_images_labels_b[:4500]\n",
    "test_images_data = test_images_data[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_images_data, open('edges_train_images_data.pck', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_images_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4b12e2bae60a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'colored_edges_test_images_data_sgd_dt4500.pck'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_images_data' is not defined"
     ]
    }
   ],
   "source": [
    "pickle.dump(test_images_data, open('colored_edges_test_images_data.pck', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_images_labels, open('edges_train_images_labels.pck', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_data = pickle.load(open('edges_train_images_data.pck', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 64, 64, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_data = pickle.load(open('edges_test_images_data.pck', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 64, 64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_labels = pickle.load(open('edges_train_images_labels.pck', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'baseline_adam_dt_9000' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14400 samples, validate on 3600 samples\n",
      "Epoch 1/100\n",
      "14400/14400 [==============================] - 23s 2ms/step - loss: 0.7734 - acc: 0.7051 - val_loss: 0.4194 - val_acc: 0.7762\n",
      "Epoch 2/100\n",
      "   96/14400 [..............................] - ETA: 20s - loss: 0.4286 - acc: 0.7708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/huangtin_cs537/miniconda3/envs/myenv/lib/python3.6/site-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.4124 - acc: 0.7847 - val_loss: 0.3800 - val_acc: 0.8074\n",
      "Epoch 3/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.3693 - acc: 0.8150 - val_loss: 0.3498 - val_acc: 0.8230\n",
      "Epoch 4/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.3393 - acc: 0.8322 - val_loss: 0.3210 - val_acc: 0.8419\n",
      "Epoch 5/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.3212 - acc: 0.8448 - val_loss: 0.3099 - val_acc: 0.8468\n",
      "Epoch 6/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.3059 - acc: 0.8544 - val_loss: 0.3009 - val_acc: 0.8502\n",
      "Epoch 7/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.2902 - acc: 0.8631 - val_loss: 0.3051 - val_acc: 0.8466\n",
      "Epoch 8/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.2781 - acc: 0.8698 - val_loss: 0.2896 - val_acc: 0.8581\n",
      "Epoch 9/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.2695 - acc: 0.8732 - val_loss: 0.2861 - val_acc: 0.8614\n",
      "Epoch 10/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.2649 - acc: 0.8766 - val_loss: 0.3042 - val_acc: 0.8484\n",
      "Epoch 11/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.2488 - acc: 0.8854 - val_loss: 0.3388 - val_acc: 0.8472\n",
      "Epoch 12/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.2442 - acc: 0.8875 - val_loss: 0.2946 - val_acc: 0.8622\n",
      "Epoch 13/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.2337 - acc: 0.8927 - val_loss: 0.2925 - val_acc: 0.8683\n",
      "Epoch 14/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.2261 - acc: 0.8969 - val_loss: 0.2864 - val_acc: 0.8668\n",
      "Epoch 15/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.2221 - acc: 0.8999 - val_loss: 0.2841 - val_acc: 0.8656\n",
      "Epoch 16/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.2180 - acc: 0.9017 - val_loss: 0.2934 - val_acc: 0.8647\n",
      "Epoch 17/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.2077 - acc: 0.9056 - val_loss: 0.2958 - val_acc: 0.8680\n",
      "Epoch 18/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1968 - acc: 0.9121 - val_loss: 0.2895 - val_acc: 0.8693\n",
      "Epoch 19/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1944 - acc: 0.9129 - val_loss: 0.2928 - val_acc: 0.8672\n",
      "Epoch 20/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1881 - acc: 0.9157 - val_loss: 0.2972 - val_acc: 0.8652\n",
      "Epoch 21/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1791 - acc: 0.9219 - val_loss: 0.3121 - val_acc: 0.8669\n",
      "Epoch 22/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1767 - acc: 0.9236 - val_loss: 0.3136 - val_acc: 0.8716\n",
      "Epoch 23/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1748 - acc: 0.9251 - val_loss: 0.3154 - val_acc: 0.8646\n",
      "Epoch 24/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1641 - acc: 0.9277 - val_loss: 0.3333 - val_acc: 0.8654\n",
      "Epoch 25/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1650 - acc: 0.9292 - val_loss: 0.3378 - val_acc: 0.8625\n",
      "Epoch 26/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1577 - acc: 0.9331 - val_loss: 0.3539 - val_acc: 0.8595\n",
      "Epoch 27/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1571 - acc: 0.9322 - val_loss: 0.3242 - val_acc: 0.8661\n",
      "Epoch 28/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1513 - acc: 0.9342 - val_loss: 0.3319 - val_acc: 0.8615\n",
      "Epoch 29/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1457 - acc: 0.9382 - val_loss: 0.3335 - val_acc: 0.8631\n",
      "Epoch 30/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1466 - acc: 0.9374 - val_loss: 0.3311 - val_acc: 0.8653\n",
      "Epoch 31/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1421 - acc: 0.9389 - val_loss: 0.3636 - val_acc: 0.8691\n",
      "Epoch 32/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1423 - acc: 0.9416 - val_loss: 0.3095 - val_acc: 0.8674\n",
      "Epoch 33/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1378 - acc: 0.9409 - val_loss: 0.3494 - val_acc: 0.8706\n",
      "Epoch 34/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1316 - acc: 0.9442 - val_loss: 0.3915 - val_acc: 0.8706\n",
      "Epoch 35/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1291 - acc: 0.9447 - val_loss: 0.3623 - val_acc: 0.8644\n",
      "Epoch 36/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1344 - acc: 0.9439 - val_loss: 0.3760 - val_acc: 0.8645\n",
      "Epoch 37/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1291 - acc: 0.9463 - val_loss: 0.3804 - val_acc: 0.8654\n",
      "Epoch 38/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1285 - acc: 0.9467 - val_loss: 0.3779 - val_acc: 0.8646\n",
      "Epoch 39/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1216 - acc: 0.9487 - val_loss: 0.3936 - val_acc: 0.8670\n",
      "Epoch 40/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1210 - acc: 0.9493 - val_loss: 0.3718 - val_acc: 0.8655\n",
      "Epoch 41/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1230 - acc: 0.9500 - val_loss: 0.4098 - val_acc: 0.8694\n",
      "Epoch 42/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1222 - acc: 0.9515 - val_loss: 0.3787 - val_acc: 0.8634\n",
      "Epoch 43/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1168 - acc: 0.9517 - val_loss: 0.3950 - val_acc: 0.8668\n",
      "Epoch 44/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1156 - acc: 0.9533 - val_loss: 0.4138 - val_acc: 0.8658\n",
      "Epoch 45/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1185 - acc: 0.9522 - val_loss: 0.3993 - val_acc: 0.8656\n",
      "Epoch 46/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1172 - acc: 0.9534 - val_loss: 0.4061 - val_acc: 0.8595\n",
      "Epoch 47/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1153 - acc: 0.9535 - val_loss: 0.4127 - val_acc: 0.8620\n",
      "Epoch 48/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1100 - acc: 0.9559 - val_loss: 0.4509 - val_acc: 0.8667\n",
      "Epoch 49/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1147 - acc: 0.9550 - val_loss: 0.4297 - val_acc: 0.8636\n",
      "Epoch 50/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1085 - acc: 0.9572 - val_loss: 0.4263 - val_acc: 0.8616\n",
      "Epoch 51/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1108 - acc: 0.9562 - val_loss: 0.4556 - val_acc: 0.8619\n",
      "Epoch 52/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1088 - acc: 0.9574 - val_loss: 0.4775 - val_acc: 0.8638\n",
      "Epoch 53/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1064 - acc: 0.9569 - val_loss: 0.4673 - val_acc: 0.8588\n",
      "Epoch 54/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1035 - acc: 0.9589 - val_loss: 0.4828 - val_acc: 0.8628\n",
      "Epoch 55/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1062 - acc: 0.9581 - val_loss: 0.4357 - val_acc: 0.8611\n",
      "Epoch 56/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1031 - acc: 0.9603 - val_loss: 0.4200 - val_acc: 0.8660\n",
      "Epoch 57/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1016 - acc: 0.9611 - val_loss: 0.4524 - val_acc: 0.8619\n",
      "Epoch 58/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0989 - acc: 0.9610 - val_loss: 0.4265 - val_acc: 0.8645\n",
      "Epoch 59/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0947 - acc: 0.9619 - val_loss: 0.5328 - val_acc: 0.8633\n",
      "Epoch 60/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0966 - acc: 0.9629 - val_loss: 0.4788 - val_acc: 0.8638\n",
      "Epoch 61/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0960 - acc: 0.9626 - val_loss: 0.4199 - val_acc: 0.8572\n",
      "Epoch 62/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1066 - acc: 0.9593 - val_loss: 0.5163 - val_acc: 0.8627\n",
      "Epoch 63/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1007 - acc: 0.9623 - val_loss: 0.4450 - val_acc: 0.8649\n",
      "Epoch 64/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0989 - acc: 0.9635 - val_loss: 0.4825 - val_acc: 0.8631\n",
      "Epoch 65/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0988 - acc: 0.9621 - val_loss: 0.4766 - val_acc: 0.8610\n",
      "Epoch 66/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0964 - acc: 0.9616 - val_loss: 0.5312 - val_acc: 0.8651\n",
      "Epoch 67/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1036 - acc: 0.9610 - val_loss: 0.5080 - val_acc: 0.8647\n",
      "Epoch 68/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0993 - acc: 0.9613 - val_loss: 0.4848 - val_acc: 0.8615\n",
      "Epoch 69/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0935 - acc: 0.9647 - val_loss: 0.4481 - val_acc: 0.8608\n",
      "Epoch 70/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1017 - acc: 0.9613 - val_loss: 0.4580 - val_acc: 0.8582\n",
      "Epoch 71/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0915 - acc: 0.9633 - val_loss: 0.5894 - val_acc: 0.8629\n",
      "Epoch 72/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0937 - acc: 0.9644 - val_loss: 0.5509 - val_acc: 0.8632\n",
      "Epoch 73/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0987 - acc: 0.9614 - val_loss: 0.4991 - val_acc: 0.8666\n",
      "Epoch 74/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0924 - acc: 0.9654 - val_loss: 0.5153 - val_acc: 0.8631\n",
      "Epoch 75/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0870 - acc: 0.9664 - val_loss: 0.5681 - val_acc: 0.8660\n",
      "Epoch 76/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0978 - acc: 0.9633 - val_loss: 0.5039 - val_acc: 0.8607\n",
      "Epoch 77/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0973 - acc: 0.9622 - val_loss: 0.4900 - val_acc: 0.8634\n",
      "Epoch 78/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0950 - acc: 0.9648 - val_loss: 0.5374 - val_acc: 0.8602\n",
      "Epoch 79/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0892 - acc: 0.9684 - val_loss: 0.5068 - val_acc: 0.8637\n",
      "Epoch 80/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0951 - acc: 0.9649 - val_loss: 0.5712 - val_acc: 0.8656\n",
      "Epoch 81/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0859 - acc: 0.9682 - val_loss: 0.6143 - val_acc: 0.8644\n",
      "Epoch 82/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1022 - acc: 0.9631 - val_loss: 0.5038 - val_acc: 0.8632\n",
      "Epoch 83/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0868 - acc: 0.9684 - val_loss: 0.5466 - val_acc: 0.8636\n",
      "Epoch 84/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0912 - acc: 0.9666 - val_loss: 0.4977 - val_acc: 0.8619\n",
      "Epoch 85/100\n",
      "14400/14400 [==============================] - 22s 1ms/step - loss: 0.0861 - acc: 0.9693 - val_loss: 0.5519 - val_acc: 0.8700\n",
      "Epoch 86/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0962 - acc: 0.9646 - val_loss: 0.4861 - val_acc: 0.8615\n",
      "Epoch 87/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0861 - acc: 0.9671 - val_loss: 0.6176 - val_acc: 0.8598\n",
      "Epoch 88/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0938 - acc: 0.9640 - val_loss: 0.5027 - val_acc: 0.8663\n",
      "Epoch 89/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0931 - acc: 0.9660 - val_loss: 0.5476 - val_acc: 0.8590\n",
      "Epoch 90/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0878 - acc: 0.9682 - val_loss: 0.4665 - val_acc: 0.8627\n",
      "Epoch 91/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0902 - acc: 0.9659 - val_loss: 0.4951 - val_acc: 0.8590\n",
      "Epoch 92/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0889 - acc: 0.9684 - val_loss: 0.5635 - val_acc: 0.8658\n",
      "Epoch 93/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0949 - acc: 0.9656 - val_loss: 0.5519 - val_acc: 0.8665\n",
      "Epoch 94/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0831 - acc: 0.9694 - val_loss: 0.5689 - val_acc: 0.8681\n",
      "Epoch 95/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0888 - acc: 0.9664 - val_loss: 0.5425 - val_acc: 0.8672\n",
      "Epoch 96/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0881 - acc: 0.9684 - val_loss: 0.5581 - val_acc: 0.8669\n",
      "Epoch 97/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0890 - acc: 0.9661 - val_loss: 0.5863 - val_acc: 0.8652\n",
      "Epoch 98/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0858 - acc: 0.9681 - val_loss: 0.6427 - val_acc: 0.8613\n",
      "Epoch 99/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0832 - acc: 0.9684 - val_loss: 0.6190 - val_acc: 0.8668\n",
      "Epoch 100/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.0853 - acc: 0.9691 - val_loss: 0.5428 - val_acc: 0.8648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4434278828>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(Conv2D(64, (5, 5), input_shape=(64, 64, 1))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1)) \n",
    "  \n",
    "model.add(Conv2D(32, (3, 3))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.1)) \n",
    "  \n",
    "model.add(Conv2D(32, (3, 3))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.1)) \n",
    "  \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(50)) #Increase to see how accuracy performs \n",
    "#consider also with 0.1 dropout it went from training with 25 to training with 45\n",
    "\n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.1)) #compare 0.5 with to 0.1 then 0.2 and 0.3\n",
    "\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "# Dense(3, activation='softmax') \n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "# writer = SummaryWriter(log_dir='./logs2/edge_plt.pth')\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(model_name))\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=8)\n",
    "checkpoint = ModelCheckpoint(filepath= model_name + '_checkpoint.h5', monitor='val_accuracy', \n",
    "                             save_best_only=True)\n",
    "\n",
    "# model.fit(train_images_data, train_images_labels, epochs=100, validation_split=0.2, \n",
    "#           callbacks=[tensorboard, early_stop, checkpoint])\n",
    "model.fit(train_images_data, train_images_labels, epochs=100, validation_split=0.2, \n",
    "          callbacks=[tensorboard, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 64, 64, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_67 (Conv2D)           (None, 60, 60, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 50)                57650     \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 3)                 6         \n",
      "=================================================================\n",
      "Total params: 87,083\n",
      "Trainable params: 87,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-2822f0814bd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m _ = m.update_state([[0, 0, 1], [0, 1, 0]],\n\u001b[1;32m      4\u001b[0m                    [[0.1, 0.9, 0.8], [0.05, 0.95, 0]])\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "tf.executing_eagerly()\n",
    "m = tf.keras.metrics.TopKCategoricalAccuracy(k=1)\n",
    "_ = m.update_state([[0, 0, 1], [0, 1, 0]],\n",
    "                   [[0.1, 0.9, 0.8], [0.05, 0.95, 0]])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
